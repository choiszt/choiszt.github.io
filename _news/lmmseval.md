---
layout: post
date: 2024-7-17
inline: true
related_posts: false
---

We introduce [LMMs-Eval](https://arxiv.org/abs/2407.12772), a comprehensive and efficient benchmark for evaluating Large Multimodal Models, alongside LMMs-Eval Lite and Multimodal [Livebench](https://huggingface.co/spaces/lmms-lab/LiveBench), which ensure low-cost and contamination-free evaluations in dynamic environments.